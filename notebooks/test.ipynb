{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ.setdefault(\"GRPC_VERBOSITY\", \"NONE\")\n",
    "os.environ.setdefault(\"GLOG_minloglevel\", \"2\")\n",
    "import pandas as pd\n",
    "from langfuse import Langfuse, get_client\n",
    "from src.pipeline_4_agent import SequentialAgentPipeline\n",
    "from src.retrieval_then_llm import SmartClassifier, run_smartclassifier\n",
    "\n",
    "# from src.sequential_agent import run_pipeline\n",
    "from src.seq_all_rag import run_pipeline\n",
    "\n",
    "langfuse = get_client()\n",
    "tickets = pd.read_csv(\"data/evaluation_dataset2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ticket': 'ÐœÑÐ³Ð¼Ð°Ñ€Ð¶Ð°Ñ€Ð³Ð°Ð» Ð‘ÑÐ¼Ð±Ð°Ð¶Ð°Ð²\\': \"Get started\"\\n\\'customer service\\': \"Ð¡Ð°Ð¹Ð½ Ð±Ð°Ð¹Ð½Ð° ÑƒÑƒ? ðŸ‘‹ Toki Ð°Ð¿Ð¿-Ñ‚Ð°Ð¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹ Ð°ÑÑƒÑƒÑ… Ð·Ò¯Ð¹Ð»ÑÑ Ð±Ð¸Ñ‡ÑÑÑ€ÑÐ¹? ðŸ˜Š\"\\n\\'ÐœÑÐ³Ð¼Ð°Ñ€Ð¶Ð°Ñ€Ð³Ð°Ð» Ð‘ÑÐ¼Ð±Ð°Ð¶Ð°Ð²\\': \"ÐÐ¶Ð¸Ð»Ñ‚Ð°Ð½Ñ‚Ð°Ð¹ Ñ…Ð¾Ð»Ð±Ð¾Ð³Ð´Ð¾Ñ…\"\\n\\'ÐœÑÐ³Ð¼Ð°Ñ€Ð¶Ð°Ñ€Ð³Ð°Ð» Ð‘ÑÐ¼Ð±Ð°Ð¶Ð°Ð²\\': \"Ð³Ð°Ñ€ ÑƒÑ‚Ð°ÑÐ½Ñ‹ Ð·ÑÑÐ» ÑÑ€Ð³ÑÐ½ ÑÐ°Ð¶ Ñ‚Ó©Ð»Ó©Ñ… Ð²Ñ\"\\n\\'customer service\\': \"Ð¡Ð°Ð¹Ð½ Ð±Ð°Ð¹Ð½Ð° ÑƒÑƒ? Ð‘Ð¸ Ð¡Ð¾Ð½Ð´Ð¾Ñ€ Ð±Ð°Ð¹Ð½Ð° ðŸ™‹\\u200dâ™€ï¸Ð¢Ð°Ð½Ð´ ÑŽÑƒÐ³Ð°Ð°Ñ€ Ñ‚ÑƒÑÐ»Ð°Ñ… Ð²Ñ?\"\\n\\'ÐœÑÐ³Ð¼Ð°Ñ€Ð¶Ð°Ñ€Ð³Ð°Ð» Ð‘ÑÐ¼Ð±Ð°Ð¶Ð°Ð²\\': \"Ð³Ð°Ñ€ ÑƒÑ‚Ð°ÑÐ½Ñ‹ Ð·ÑÑÐ» Ñ‚Ó©Ð»Ó©Ñ… Ð³ÑÑÑÐ½ Ñ…Ð°Ð°ÑˆÐ°Ð° ÑÐ°Ð¶ Ð¾Ñ€Ð¶ Ñ‚Ó©Ð»Ó©Ñ… Ð²Ñ?\"\\n\\'customer service\\': \"Ð¢Ð° Ð¥ÑÑ‚ÑÐ²Ñ‡- Toki Ð»Ð¸Ð·Ð¸Ð½Ð³ Ñ†ÑÑÑÑÑ€ Ñ…Ð°Ð½Ð´Ð°Ð°Ð´ Ñ‚Ó©Ð»Ð±Ó©Ñ€ Ñ‚Ó©Ð»Ó©Ð»Ñ‚Ó©Ó© Ñ…Ð¸Ð¹Ð³ÑÑÑ€ÑÐ¹.\"', 'domain': 'Toki', 'category_1': 'Ð¥ÑÑ‚ÑÐ²Ñ‡', 'category_2': 'ÐšÑ€ÐµÐ´Ð¸Ñ‚ ÑÑ€Ð³ÑÐ½ Ñ‚Ó©Ð»Ó©Ð»Ñ‚Ñ‚ÑÐ¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹', 'category_3': 'L2-Ð­Ñ€Ð³ÑÐ½ Ñ‚Ó©Ð»Ó©Ð»Ñ‚ Ð¾Ñ€ÑƒÑƒÐ»ÑÐ°Ð½'}\n"
     ]
    }
   ],
   "source": [
    "faa = run_pipeline(tickets.at[6, \"ticket\"], \"data/cleaned.csv\")\n",
    "print(faa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing taxonomy from data/cleaned.csv...\n"
     ]
    }
   ],
   "source": [
    "pipeline = SequentialAgentPipeline(\"data/cleaned.csv\")\n",
    "final_categorizations = []\n",
    "kb_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "{'best_path': {'L1_domain': {'id': 'dom.1b59a5fdf0ef', 'confidence': 0.9, 'name': 'Toki'}, 'L2_cat1': {'id': 'cat1.38f67d7524e1', 'confidence': 0.9, 'name': 'Ò®Ð¹Ð»Ñ‡Ð¸Ð»Ð³ÑÑ'}, 'L3_cat2': {'id': 'cat2.aae242753c1c', 'confidence': 0.85, 'name': 'Ð“Ð°Ñ€ ÑƒÑ‚Ð°Ñ Ð»Ð¸Ð·Ð¸Ð½Ð³'}, 'L4_cat3': {'id': 'cat3.b3c7195654a0', 'confidence': 0.85, 'name': 'Ð¢Ó©Ñ…Ó©Ó©Ñ€Ó©Ð¼Ð¶ Ð±Ð¾Ð»Ð¾Ð½ Ð´Ð°Ð³Ð°Ð»Ð´Ð°Ñ… Ñ…ÑÑ€ÑÐ³ÑÑÐ»Ñ‚ÑÐ¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹'}}, 'rationale': 'Ð¡Ð¾Ð½Ð³Ð¾ÑÐ¾Ð½ Ð·Ð°Ð¼: Toki > Ò®Ð¹Ð»Ñ‡Ð¸Ð»Ð³ÑÑ > Ð“Ð°Ñ€ ÑƒÑ‚Ð°Ñ Ð»Ð¸Ð·Ð¸Ð½Ð³ > Ð¢Ó©Ñ…Ó©Ó©Ñ€Ó©Ð¼Ð¶ Ð±Ð¾Ð»Ð¾Ð½ Ð´Ð°Ð³Ð°Ð»Ð´Ð°Ñ… Ñ…ÑÑ€ÑÐ³ÑÑÐ»Ñ‚ÑÐ¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹. Ð¥ÑÑ€ÑÐ³Ð»ÑÐ³Ñ‡ \"Ð³Ð°Ñ€ ÑƒÑ‚Ð°ÑÐ½Ñ‹ Ð·ÑÑÐ»\" Ð±Ð¾Ð»Ð¾Ð½ \"Ð³Ð°Ñ€ ÑƒÑ‚Ð°ÑÐ½Ñ‹ Ð·ÑÑÐ» Ñ‚Ó©Ð»Ó©Ñ…\" Ñ‚Ð°Ð»Ð°Ð°Ñ€ Ð°ÑÑƒÑƒÐ¶, Ð»Ð¸Ð·Ð¸Ð½Ð³/Ð·ÑÑÐ»Ñ‚ÑÐ¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹ Ñ‚Ó©Ð»Ð±Ó©Ñ€ Ñ…Ð¸Ð¹Ñ… Ð·Ð°Ð°Ð²Ñ€Ñ‹Ð³ Ñ…Ò¯ÑÑÑÐ½ ÑƒÑ‡Ñ€Ð°Ð°Ñ Ð³Ð°Ñ€ ÑƒÑ‚Ð°Ñ Ð»Ð¸Ð·Ð¸Ð½Ð³ Ñ‚Ó©Ñ€Ó©Ð»Ð´ Ñ…Ð°Ð¼Ð³Ð¸Ð¹Ð½ Ñ‚Ð¾Ñ…Ð¸Ñ€Ð½Ð¾.', 'abstain': False, 'selected_index': 4, 'path_mn': 'Toki > Ò®Ð¹Ð»Ñ‡Ð¸Ð»Ð³ÑÑ > Ð“Ð°Ñ€ ÑƒÑ‚Ð°Ñ Ð»Ð¸Ð·Ð¸Ð½Ð³ > Ð¢Ó©Ñ…Ó©Ó©Ñ€Ó©Ð¼Ð¶ Ð±Ð¾Ð»Ð¾Ð½ Ð´Ð°Ð³Ð°Ð»Ð´Ð°Ñ… Ñ…ÑÑ€ÑÐ³ÑÑÐ»Ñ‚ÑÐ¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹'}\n"
     ]
    }
   ],
   "source": [
    "xd = await run_smartclassifier(tickets.at[6, \"ticket\"])\n",
    "print(xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ticket': 'ÐœÑÐ³Ð¼Ð°Ñ€Ð¶Ð°Ñ€Ð³Ð°Ð» Ð‘ÑÐ¼Ð±Ð°Ð¶Ð°Ð²\\': \"Get started\"\\n\\'customer service\\': \"Ð¡Ð°Ð¹Ð½ Ð±Ð°Ð¹Ð½Ð° ÑƒÑƒ? ðŸ‘‹ Toki Ð°Ð¿Ð¿-Ñ‚Ð°Ð¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹ Ð°ÑÑƒÑƒÑ… Ð·Ò¯Ð¹Ð»ÑÑ Ð±Ð¸Ñ‡ÑÑÑ€ÑÐ¹? ðŸ˜Š\"\\n\\'ÐœÑÐ³Ð¼Ð°Ñ€Ð¶Ð°Ñ€Ð³Ð°Ð» Ð‘ÑÐ¼Ð±Ð°Ð¶Ð°Ð²\\': \"ÐÐ¶Ð¸Ð»Ñ‚Ð°Ð½Ñ‚Ð°Ð¹ Ñ…Ð¾Ð»Ð±Ð¾Ð³Ð´Ð¾Ñ…\"\\n\\'ÐœÑÐ³Ð¼Ð°Ñ€Ð¶Ð°Ñ€Ð³Ð°Ð» Ð‘ÑÐ¼Ð±Ð°Ð¶Ð°Ð²\\': \"Ð³Ð°Ñ€ ÑƒÑ‚Ð°ÑÐ½Ñ‹ Ð·ÑÑÐ» ÑÑ€Ð³ÑÐ½ ÑÐ°Ð¶ Ñ‚Ó©Ð»Ó©Ñ… Ð²Ñ\"\\n\\'customer service\\': \"Ð¡Ð°Ð¹Ð½ Ð±Ð°Ð¹Ð½Ð° ÑƒÑƒ? Ð‘Ð¸ Ð¡Ð¾Ð½Ð´Ð¾Ñ€ Ð±Ð°Ð¹Ð½Ð° ðŸ™‹\\u200dâ™€ï¸Ð¢Ð°Ð½Ð´ ÑŽÑƒÐ³Ð°Ð°Ñ€ Ñ‚ÑƒÑÐ»Ð°Ñ… Ð²Ñ?\"\\n\\'ÐœÑÐ³Ð¼Ð°Ñ€Ð¶Ð°Ñ€Ð³Ð°Ð» Ð‘ÑÐ¼Ð±Ð°Ð¶Ð°Ð²\\': \"Ð³Ð°Ñ€ ÑƒÑ‚Ð°ÑÐ½Ñ‹ Ð·ÑÑÐ» Ñ‚Ó©Ð»Ó©Ñ… Ð³ÑÑÑÐ½ Ñ…Ð°Ð°ÑˆÐ°Ð° ÑÐ°Ð¶ Ð¾Ñ€Ð¶ Ñ‚Ó©Ð»Ó©Ñ… Ð²Ñ?\"\\n\\'customer service\\': \"Ð¢Ð° Ð¥ÑÑ‚ÑÐ²Ñ‡- Toki Ð»Ð¸Ð·Ð¸Ð½Ð³ Ñ†ÑÑÑÑÑ€ Ñ…Ð°Ð½Ð´Ð°Ð°Ð´ Ñ‚Ó©Ð»Ð±Ó©Ñ€ Ñ‚Ó©Ð»Ó©Ð»Ñ‚Ó©Ó© Ñ…Ð¸Ð¹Ð³ÑÑÑ€ÑÐ¹.\"', 'domain': 'Toki', 'category_1': 'Ð¥ÑÑ‚ÑÐ²Ñ‡', 'category_2': 'ÐšÑ€ÐµÐ´Ð¸Ñ‚ ÑÑ€Ð³ÑÐ½ Ñ‚Ó©Ð»Ó©Ð»Ñ‚Ñ‚ÑÐ¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹', 'category_3': 'L2-Ð­Ñ€Ð³ÑÐ½ Ñ‚Ó©Ð»Ó©Ð»Ñ‚ Ð¾Ñ€ÑƒÑƒÐ»ÑÐ°Ð½'}\n"
     ]
    }
   ],
   "source": [
    "susta = run_pipeline(tickets.at[6, \"ticket\"], \"data/cleaned.csv\")\n",
    "print(susta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "{'best_path': {'L1_domain': {'id': 'dom.1b59a5fdf0ef', 'confidence': 0.9, 'name': 'Toki'}, 'L2_cat1': {'id': 'cat1.38f67d7524e1', 'confidence': 0.9, 'name': 'Ò®Ð¹Ð»Ñ‡Ð¸Ð»Ð³ÑÑ'}, 'L3_cat2': {'id': 'cat2.aae242753c1c', 'confidence': 0.85, 'name': 'Ð“Ð°Ñ€ ÑƒÑ‚Ð°Ñ Ð»Ð¸Ð·Ð¸Ð½Ð³'}, 'L4_cat3': {'id': 'cat3.b3c7195654a0', 'confidence': 0.85, 'name': 'Ð¢Ó©Ñ…Ó©Ó©Ñ€Ó©Ð¼Ð¶ Ð±Ð¾Ð»Ð¾Ð½ Ð´Ð°Ð³Ð°Ð»Ð´Ð°Ñ… Ñ…ÑÑ€ÑÐ³ÑÑÐ»Ñ‚ÑÐ¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹'}}, 'rationale': 'Ð¡Ð¾Ð½Ð³Ð¾ÑÐ¾Ð½ Ð·Ð°Ð¼: Toki > Ò®Ð¹Ð»Ñ‡Ð¸Ð»Ð³ÑÑ > Ð“Ð°Ñ€ ÑƒÑ‚Ð°Ñ Ð»Ð¸Ð·Ð¸Ð½Ð³ > Ð¢Ó©Ñ…Ó©Ó©Ñ€Ó©Ð¼Ð¶ Ð±Ð¾Ð»Ð¾Ð½ Ð´Ð°Ð³Ð°Ð»Ð´Ð°Ñ… Ñ…ÑÑ€ÑÐ³ÑÑÐ»Ñ‚ÑÐ¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹. Ð¥ÑÑ€ÑÐ³Ð»ÑÐ³Ñ‡ \"Ð³Ð°Ñ€ ÑƒÑ‚Ð°ÑÐ½Ñ‹ Ð·ÑÑÐ»/Ð»Ð¸Ð·Ð¸Ð½Ð³ ÑÑ€Ð³ÑÐ½ Ñ‚Ó©Ð»Ó©Ñ…\" Ñ‚Ð°Ð»Ð°Ð°Ñ€ Ð·Ð°Ð°Ð²Ð°Ñ€ Ñ…Ò¯ÑÑÐ¶ Ð±Ð°Ð¹Ð³Ð°Ð°Ð³Ð°Ð°Ñ ÑÐ½Ñ Ð½ÑŒ Ð³Ð°Ñ€ ÑƒÑ‚Ð°Ñ Ð»Ð¸Ð·Ð¸Ð½Ð³, Ñ‚Ó©Ñ…Ó©Ó©Ñ€Ó©Ð¼Ð¶Ñ‚ÑÐ¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹ Ñ…Ð°Ð¼Ð³Ð¸Ð¹Ð½ Ñ‚Ð¾Ñ…Ð¸Ñ€Ð¾Ñ… Ð°Ð½Ð³Ð¸Ð»Ð°Ð» Ð³ÑÐ¶ Ò¯Ð·ÑÐ².', 'abstain': False, 'selected_index': 4, 'path_mn': 'Toki > Ò®Ð¹Ð»Ñ‡Ð¸Ð»Ð³ÑÑ > Ð“Ð°Ñ€ ÑƒÑ‚Ð°Ñ Ð»Ð¸Ð·Ð¸Ð½Ð³ > Ð¢Ó©Ñ…Ó©Ó©Ñ€Ó©Ð¼Ð¶ Ð±Ð¾Ð»Ð¾Ð½ Ð´Ð°Ð³Ð°Ð»Ð´Ð°Ñ… Ñ…ÑÑ€ÑÐ³ÑÑÐ»Ñ‚ÑÐ¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹'}\n",
      "Toki>Ð¥ÑÑ‚ÑÐ²Ñ‡>ÐšÑ€ÐµÐ´Ð¸Ñ‚ ÑÑ€Ð³ÑÐ½ Ñ‚Ó©Ð»Ó©Ð»Ñ‚Ñ‚ÑÐ¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹>L2-Ð­Ñ€Ð³ÑÐ½ Ñ‚Ó©Ð»Ó©Ð»Ñ‚ Ð¾Ñ€ÑƒÑƒÐ»ÑÐ°Ð½\n"
     ]
    }
   ],
   "source": [
    "basta = await pipeline.run(tickets.at[6, \"ticket\"])\n",
    "langfuse.shutdown()\n",
    "susta = await run_pipeline(tickets.at[6, \"ticket\"], \"data/cleaned.csv\")\n",
    "print(susta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobile>Ð”Ð°Ñ‚Ð°>Ð”Ð°Ñ‚Ð° Ð±Ð°Ð³Ñ†ÑƒÑƒÐ´Ñ‚Ð°Ð¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹>Other/Unknown\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>Ð”ÑƒÐ³Ð°Ð°Ñ€>Ð”ÑƒÐ³Ð°Ð°Ñ€ Ñ…Ð°Ð´Ð³Ð°Ð»Ð°Ñ…Ñ‚Ð°Ð¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹>L2-Ð”ÑƒÐ³Ð°Ð°Ñ€ Ñ…Ð°Ð´Ð³Ð°Ð»ÑƒÑƒÐ»Ð°Ñ… Ñ…Ò¯ÑÑÐ»Ñ‚\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Path terminates at Cat2 for 'Mobile -> Ò®Ð½Ð´ÑÑÐ½ Ò¯Ð¹Ð»Ñ‡Ð¸Ð»Ð³ÑÑ -> Ð“Ð°Ñ€ ÑƒÑ‚Ð°ÑÐ½Ñ‹ Ñ‚Ð¾Ñ…Ð¸Ñ€Ð³Ð¾Ð¾Ñ‚Ð¾Ð¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹'.\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>Ð”ÑƒÐ³Ð°Ð°Ñ€>Ð¨Ð¸Ð½Ñ Ñ…ÑÑ€ÑÐ³Ð»ÑÐ³Ñ‡Ñ‚ÑÐ¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹>L2-Unitel app ÑˆÐ¸Ð½Ñ Ð´ÑƒÐ³Ð°Ð°Ñ€Ñ‹Ð½ QR ÑƒÐ½ÑˆÐ¸Ð³Ð´Ð°Ñ…Ð³Ò¯Ð¹ Ð±Ð°Ð¹Ð³Ð°Ð°Ð³Ð°Ð°Ñ ÑˆÐ°Ð»Ñ‚Ð³Ð°Ð°Ð»ÑÐ°Ð½\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Path terminates at Cat2 for 'Mobile -> ÐÑÐ¼ÑÐ»Ñ‚ Ò¯Ð¹Ð»Ñ‡Ð¸Ð»Ð³ÑÑ -> Ð¥Ò¯ÑÑÐ»Ñ‚ Ð½ÑÐ¼ÑÐ»Ñ‚ Ò¯Ð¹Ð»Ñ‡Ð¸Ð»Ð³ÑÑ-1444'.\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>ÐÑÐ³Ð¶>Ð¦ÑÐ½ÑÐ³Ð»ÑÐ³Ñ‡ ÐºÐ°Ñ€Ñ‚Ñ‚Ð°Ð¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹>L2-Ð¥ÑÑ€ÑÐ³Ð»ÑÐ³Ñ‡ÑÑÑ ÑˆÐ°Ð»Ñ‚Ð³Ð°Ð°Ð»ÑÐ°Ð½\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>Ð”ÑƒÐ³Ð°Ð°Ñ€>Ð”ÑƒÐ³Ð°Ð°Ñ€ Ñ…Ð°Ð°Ð¶, Ð½ÑÑÐ»Ð³ÑÑ…Ñ‚ÑÐ¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹>L2-Ð”ÑƒÐ³Ð°Ð°Ñ€ ÑƒÑÑ‚Ð³ÑƒÑƒÐ»Ð°Ñ… Ñ…Ò¯ÑÑÐ»Ñ‚\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Path terminates at Cat2 for 'Mobile -> Ò®Ð½Ð´ÑÑÐ½ Ò¯Ð¹Ð»Ñ‡Ð¸Ð»Ð³ÑÑ -> Ð“Ð°Ñ€ ÑƒÑ‚Ð°ÑÐ½Ñ‹ Ñ‚Ð¾Ñ…Ð¸Ñ€Ð³Ð¾Ð¾Ñ‚Ð¾Ð¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹'.\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Path terminates at Cat2 for 'Mobile -> ÐÑÐ¼ÑÐ»Ñ‚ Ò¯Ð¹Ð»Ñ‡Ð¸Ð»Ð³ÑÑ -> Ð¥Ò¯ÑÑÐ»Ñ‚ Ð½ÑÐ¼ÑÐ»Ñ‚ Ò¯Ð¹Ð»Ñ‡Ð¸Ð»Ð³ÑÑ-1444'.\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>ÐÑÐ¼ÑÐ»Ñ‚ Ò¯Ð¹Ð»Ñ‡Ð¸Ð»Ð³ÑÑ>Ð”ÑƒÑƒÐ´Ð»Ð°Ð³Ð° ÑˆÐ¸Ð»Ð¶Ò¯Ò¯Ð»ÑÑ… Ò¯Ð¹Ð»Ñ‡Ð¸Ð»Ð³ÑÑ>L2- Ð”ÑƒÑƒÐ´Ð»Ð°Ð³Ð° ÑˆÐ¸Ð»Ð¶Ò¯Ò¯Ð»ÑÑ… Ñ…Ò¯ÑÑÐ»Ñ‚\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>Ð”Ð°Ñ‚Ð°>Ð”Ð°Ñ‚Ð° ÑƒÐ½ÑˆÐ¸Ñ…Ð³Ò¯Ð¹, Ñ…ÑƒÑ€Ð´ ÑƒÐ´Ð°Ð°Ð½ Ð±Ð°Ð¹Ð³Ð°Ð°>L1-Ð”Ð°Ñ‚Ð° Ñ…ÑƒÑ€Ð´ ÑƒÐ½Ð°Ð°Ð³Ò¯Ð¹ Ñ…ÑÑ€ÑÐ³Ð»ÑÐ³Ñ‡ÑÑÑ ÑˆÐ°Ð»Ñ‚Ð³Ð°Ð°Ð»ÑÐ°Ð½\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Path terminates at Cat2 for 'Mobile -> Ò®Ð½Ð´ÑÑÐ½ Ò¯Ð¹Ð»Ñ‡Ð¸Ð»Ð³ÑÑ -> Ð“Ð°Ñ€ ÑƒÑ‚Ð°ÑÐ½Ñ‹ Ñ‚Ð¾Ñ…Ð¸Ñ€Ð³Ð¾Ð¾Ñ‚Ð¾Ð¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹'.\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Toki>Ð‘Ò¯Ñ€Ñ‚Ð³ÑÐ», Ñ‚Ð¾Ñ…Ð¸Ñ€Ð³Ð¾Ð¾>Ð“Ò¯Ð¹Ð»Ð³ÑÑÐ½Ð¸Ð¹ Ð½ÑƒÑƒÑ† Ò¯Ð³Ñ‚ÑÐ¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹>L2-ÐÑƒÑƒÑ† Ò¯Ð³ ÑÑÑ€Ð³ÑÑÑ… OTP ÐºÐ¾Ð´ Ð¸Ñ€ÑÑÐ³Ò¯Ð¹\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Path terminates at Cat2 for 'Mobile -> Ò®Ð½Ð´ÑÑÐ½ Ò¯Ð¹Ð»Ñ‡Ð¸Ð»Ð³ÑÑ -> Ð“Ð°Ñ€ ÑƒÑ‚Ð°ÑÐ½Ñ‹ Ñ‚Ð¾Ñ…Ð¸Ñ€Ð³Ð¾Ð¾Ñ‚Ð¾Ð¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹'.\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>Ð”ÑƒÐ³Ð°Ð°Ñ€>Ð”ÑƒÑƒÐ´Ð»Ð°Ð³Ð° Ñ…Ð¸Ð¹Ð¶ Ð±Ð¾Ð»Ð¾Ñ…Ð³Ò¯Ð¹ Ð±Ð°Ð¹Ð³Ð°Ð°>L2-Ð¥ÑÑ€ÑÐ³Ð»ÑÐ³Ñ‡ÑÑÑ ÑˆÐ°Ð»Ñ‚Ð³Ð°Ð°Ð»ÑÐ°Ð½ Ð´ÑƒÑƒÐ´Ð»Ð°Ð³Ð° Ñ…Ð¸Ð¹Ñ…ÑÐ´ Ñ…ÑÐ²Ð¸Ð¹Ð½\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Toki>Toki Mobile>Ð”ÑƒÐ³Ð°Ð°Ñ€>Other/Unknown\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>Ð”Ð°Ñ‚Ð°>Ð—Ð°Ñ€Ñ†ÑƒÑƒÐ»Ð°Ð»Ñ‚Ñ‚Ð°Ð¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹>L2-Ð¥ÑÑ€ÑÐ³Ð»ÑÐ³Ñ‡ Ñ…ÑÑ€ÑÐ³Ð»ÑÑÐ³ÑÑ Ñ…Ò¯Ð»ÑÑÐ½ Ð·Ó©Ð²ÑˆÓ©Ó©Ñ€Ó©Ó©Ð³Ò¯Ð¹Ð³ÑÑÑ ÑˆÐ°Ð»Ñ‚Ð³Ð°Ð°Ð»ÑÐ°Ð½\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>Ð”ÑƒÐ³Ð°Ð°Ñ€>Ð”ÑƒÐ³Ð°Ð°Ñ€ Ñ…Ð°Ð°Ð¶, Ð½ÑÑÐ»Ð³ÑÑ…Ñ‚ÑÐ¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹>L2-Ð”ÑƒÐ³Ð°Ð°Ñ€ Ð½ÑÑÑ…ÑÐ´ /Reactivation Required/ Ð°Ð»Ð´Ð°Ð° Ð·Ð°Ð°ÑÐ½Ð°Ð°Ñ ÑˆÐ°Ð»Ñ‚Ð³Ð°Ð°Ð»ÑÐ°Ð½*\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>Ð”ÑƒÐ³Ð°Ð°Ñ€>Ð”ÑƒÐ³Ð°Ð°Ñ€ Ñ…Ð°Ð´Ð³Ð°Ð»Ð°Ñ…Ñ‚Ð°Ð¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹>L2-Unitel app-Ñ€ Ð´ÑƒÐ³Ð°Ð°Ñ€ Ñ…Ð°Ð´Ð³Ð°Ð»Ð°Ñ… Ò¯Ð¹Ð»Ñ‡Ð¸Ð»Ð³ÑÑ Ð°Ð¼Ð¶Ð¸Ð»Ñ‚Ð³Ò¯Ð¹ Ð±Ð¾Ð»ÑÐ½Ð¾Ð¾Ñ ÑˆÐ°Ð»Ñ‚Ð³Ð°Ð°Ð»ÑÐ°Ð½*\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>Ð”Ð°Ñ‚Ð°>Ð”Ð°Ñ‚Ð° Ò¯Ð»Ð´ÑÐ³Ð´ÑÐ»Ñ‚ÑÐ¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹>L2-Ð”Ð°Ñ‚Ð° Ò¯Ð»Ð´ÑÐ³Ð´ÑÐ» Ð±ÑƒÑ€ÑƒÑƒ Ñ…Ð°Ñ€ÑƒÑƒÐ»ÑÐ°Ð½Ð°Ð°Ñ ÑˆÐ°Ð»Ñ‚Ð³Ð°Ð°Ð»ÑÐ°Ð½*\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>Ð”ÑƒÐ³Ð°Ð°Ñ€>Ð¨Ð¸Ð½Ñ Ñ…ÑÑ€ÑÐ³Ð»ÑÐ³Ñ‡Ñ‚ÑÐ¹ Ñ…Ð¾Ð»Ð±Ð¾Ð¾Ñ‚Ð¾Ð¹>Other/Unknown\n",
      "Initializing Smart Classifier (Domainâ†’Cat1â†’Cat2â†’Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n"
     ]
    }
   ],
   "source": [
    "for ticket in tickets['case']:\n",
    "    final_categorization = await pipeline.run(ticket)\n",
    "    result = await run_smartclassifier(ticket)\n",
    "    keys_in_order = [\"domain\", \"category_1\", \"category_2\", \"category_3\"]\n",
    "    valid_parts = [final_categorization.get(key) for key in keys_in_order]\n",
    "    non_empty_parts = [\n",
    "        part for part in valid_parts if part is not None and str(part).strip() != ''\n",
    "    ]\n",
    "    output = \" > \".join(non_empty_parts)\n",
    "    final_categorizations.append(output)\n",
    "    kb_results.append(result[\"path_mn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets['seq agent'] = final_categorizations\n",
    "tickets['kb agent'] = kb_results\n",
    "tickets.to_csv(\"data/evaluatednewfile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell5 â€” quick scores/preview\n",
    "import pandas as pd\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "df = pd.read_csv(\"data/evaluatedtwofold.csv\")\n",
    "\n",
    "\n",
    "def part_match(a: str, b: str) -> float:\n",
    "    \"\"\"\n",
    "    Compares path parts separated by '>' and returns the ratio of matching,\n",
    "    order-sensitive, left-to-right (prefix) matches.\n",
    "    \"\"\"\n",
    "    if not isinstance(a, str):\n",
    "        a = \"\"\n",
    "    if not isinstance(b, str):\n",
    "        b = \"\"\n",
    "    pa = [p.strip() for p in a.split(\">\") if str(p).strip()]\n",
    "    pb = [p.strip() for p in b.split(\">\") if str(p).strip()]\n",
    "    if not pa and not pb:\n",
    "        return 1.0\n",
    "    match = 0\n",
    "    for i, (xa, xb) in enumerate(zip(pa, pb)):\n",
    "        if xa == xb:\n",
    "            match += 1\n",
    "        else:\n",
    "            break  # stop at first mismatch (prefix agreement)\n",
    "    denom = max(len(pa), len(pb)) or 1\n",
    "    return match / denom\n",
    "\n",
    "\n",
    "def safe_str(x):\n",
    "    return \"\" if pd.isna(x) else str(x)\n",
    "\n",
    "\n",
    "# Choose which model columns you want to compare against the employee column\n",
    "EMP_COL = \"employee\"\n",
    "SEQ_COL = \"seq agent\"\n",
    "KB_COL = \"kb agent\"\n",
    "\n",
    "df[\"Fuzzy similarity\"] = df.apply(\n",
    "    lambda r: fuzz.token_set_ratio(safe_str(r[EMP_COL]), safe_str(r[SEQ_COL])) / 100.0,\n",
    "    axis=1,\n",
    ")\n",
    "df[\"Fuzzy similarity (kb)\"] = df.apply(\n",
    "    lambda r: fuzz.token_set_ratio(safe_str(r[EMP_COL]), safe_str(r[KB_COL])) / 100.0,\n",
    "    axis=1,\n",
    ")\n",
    "df[\"Part match (seq)\"] = df.apply(\n",
    "    lambda r: part_match(safe_str(r[EMP_COL]), safe_str(r[SEQ_COL])), axis=1\n",
    ")\n",
    "df[\"Part match (kb)\"] = df.apply(\n",
    "    lambda r: part_match(safe_str(r[EMP_COL]), safe_str(r[KB_COL])), axis=1\n",
    ")\n",
    "\n",
    "# Optional: if you later add 2.5 variants, repeat with those columns:\n",
    "for col in [\"seq agent 2.5\", \"kb agent 2.5\"]:\n",
    "    if col in df.columns:\n",
    "        df[f\"Fuzzy similarity ({col})\"] = df.apply(\n",
    "            lambda r: fuzz.token_set_ratio(safe_str(r[EMP_COL]), safe_str(r[col]))\n",
    "            / 100.0,\n",
    "            axis=1,\n",
    "        )\n",
    "        df[f\"Part match ({col})\"] = df.apply(\n",
    "            lambda r: part_match(safe_str(r[EMP_COL]), safe_str(r[col])), axis=1\n",
    "        )\n",
    "\n",
    "preview_cols = [\n",
    "    \"Case ID\",\n",
    "    \"ticket\",\n",
    "    \"employee\",\n",
    "    SEQ_COL,\n",
    "    KB_COL,\n",
    "    \"Fuzzy similarity\",\n",
    "    \"Fuzzy similarity (kb)\",\n",
    "    \"Part match (seq)\",\n",
    "    \"Part match (kb)\",\n",
    "] + [\n",
    "    c\n",
    "    for c in df.columns\n",
    "    if c.startswith(\"Fuzzy similarity (seq agent 2.5\")\n",
    "    or c.startswith(\"Fuzzy similarity (kb agent 2.5\")\n",
    "]\n",
    "preview = df[[c for c in preview_cols if c in df.columns]].head(10)\n",
    "\n",
    "# Save and show\n",
    "out_path = \"data/scored_evaluation.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "print(f\"Saved: {out_path}\")\n",
    "preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = await classifier.classify(tickets.at[6, \"ticket\"])\n",
    "print(xd)\n",
    "basta = await pipeline.run(tickets.at[6, \"ticket\"])\n",
    "langfuse.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
