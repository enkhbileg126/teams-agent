{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ.setdefault(\"GRPC_VERBOSITY\", \"NONE\")\n",
    "os.environ.setdefault(\"GLOG_minloglevel\", \"2\")\n",
    "import pandas as pd\n",
    "from langfuse import Langfuse, get_client\n",
    "from src.pipeline_4_agent import SequentialAgentPipeline\n",
    "from src.retrieval_then_llm import SmartClassifier, run_smartclassifier\n",
    "\n",
    "# from src.sequential_agent import run_pipeline\n",
    "from src.seq_all_rag import run_pipeline\n",
    "\n",
    "langfuse = get_client()\n",
    "tickets = pd.read_csv(\"data/evaluation_dataset2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ticket': '–ú—è–≥–º–∞—Ä–∂–∞—Ä–≥–∞–ª –ë—è–º–±–∞–∂–∞–≤\\': \"Get started\"\\n\\'customer service\\': \"–°–∞–π–Ω –±–∞–π–Ω–∞ —É—É? üëã Toki –∞–ø–ø-—Ç–∞–π —Ö–æ–ª–±–æ–æ—Ç–æ–π –∞—Å—É—É—Ö –∑“Ø–π–ª—ç—ç –±–∏—á—ç—ç—Ä—ç–π? üòä\"\\n\\'–ú—è–≥–º–∞—Ä–∂–∞—Ä–≥–∞–ª –ë—è–º–±–∞–∂–∞–≤\\': \"–ê–∂–∏–ª—Ç–∞–Ω—Ç–∞–π —Ö–æ–ª–±–æ–≥–¥–æ—Ö\"\\n\\'–ú—è–≥–º–∞—Ä–∂–∞—Ä–≥–∞–ª –ë—è–º–±–∞–∂–∞–≤\\': \"–≥–∞—Ä —É—Ç–∞—Å–Ω—ã –∑—ç—ç–ª —ç—Ä–≥—ç–Ω —è–∞–∂ —Ç”©–ª”©—Ö –≤—ç\"\\n\\'customer service\\': \"–°–∞–π–Ω –±–∞–π–Ω–∞ —É—É? –ë–∏ –°–æ–Ω–¥–æ—Ä –±–∞–π–Ω–∞ üôã\\u200d‚ôÄÔ∏è–¢–∞–Ω–¥ —é—É–≥–∞–∞—Ä —Ç—É—Å–ª–∞—Ö –≤—ç?\"\\n\\'–ú—è–≥–º–∞—Ä–∂–∞—Ä–≥–∞–ª –ë—è–º–±–∞–∂–∞–≤\\': \"–≥–∞—Ä —É—Ç–∞—Å–Ω—ã –∑—ç—ç–ª —Ç”©–ª”©—Ö –≥—ç—Å—ç–Ω —Ö–∞–∞—à–∞–∞ —è–∞–∂ –æ—Ä–∂ —Ç”©–ª”©—Ö –≤—ç?\"\\n\\'customer service\\': \"–¢–∞ –•—ç—Ç—ç–≤—á- Toki –ª–∏–∑–∏–Ω–≥ —Ü—ç—Å—ç—ç—Ä —Ö–∞–Ω–¥–∞–∞–¥ —Ç”©–ª–±”©—Ä —Ç”©–ª”©–ª—Ç”©”© —Ö–∏–π–≥—ç—ç—Ä—ç–π.\"', 'domain': 'Toki', 'category_1': '–•—ç—Ç—ç–≤—á', 'category_2': '–ö—Ä–µ–¥–∏—Ç —ç—Ä–≥—ç–Ω —Ç”©–ª”©–ª—Ç—Ç—ç–π —Ö–æ–ª–±–æ–æ—Ç–æ–π', 'category_3': 'L2-–≠—Ä–≥—ç–Ω —Ç”©–ª”©–ª—Ç –æ—Ä—É—É–ª—Å–∞–Ω'}\n"
     ]
    }
   ],
   "source": [
    "faa = run_pipeline(tickets.at[6, \"ticket\"], \"data/cleaned.csv\")\n",
    "print(faa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing taxonomy from data/cleaned.csv...\n"
     ]
    }
   ],
   "source": [
    "pipeline = SequentialAgentPipeline(\"data/cleaned.csv\")\n",
    "final_categorizations = []\n",
    "kb_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "{'best_path': {'L1_domain': {'id': 'dom.1b59a5fdf0ef', 'confidence': 0.9, 'name': 'Toki'}, 'L2_cat1': {'id': 'cat1.38f67d7524e1', 'confidence': 0.9, 'name': '“Æ–π–ª—á–∏–ª–≥—ç—ç'}, 'L3_cat2': {'id': 'cat2.aae242753c1c', 'confidence': 0.85, 'name': '–ì–∞—Ä —É—Ç–∞—Å –ª–∏–∑–∏–Ω–≥'}, 'L4_cat3': {'id': 'cat3.b3c7195654a0', 'confidence': 0.85, 'name': '–¢”©—Ö”©”©—Ä”©–º–∂ –±–æ–ª–æ–Ω –¥–∞–≥–∞–ª–¥–∞—Ö —Ö—ç—Ä—ç–≥—Å—ç–ª—Ç—ç–π —Ö–æ–ª–±–æ–æ—Ç–æ–π'}}, 'rationale': '–°–æ–Ω–≥–æ—Å–æ–Ω –∑–∞–º: Toki > “Æ–π–ª—á–∏–ª–≥—ç—ç > –ì–∞—Ä —É—Ç–∞—Å –ª–∏–∑–∏–Ω–≥ > –¢”©—Ö”©”©—Ä”©–º–∂ –±–æ–ª–æ–Ω –¥–∞–≥–∞–ª–¥–∞—Ö —Ö—ç—Ä—ç–≥—Å—ç–ª—Ç—ç–π —Ö–æ–ª–±–æ–æ—Ç–æ–π. –•—ç—Ä—ç–≥–ª—ç–≥—á \"–≥–∞—Ä —É—Ç–∞—Å–Ω—ã –∑—ç—ç–ª\" –±–æ–ª–æ–Ω \"–≥–∞—Ä —É—Ç–∞—Å–Ω—ã –∑—ç—ç–ª —Ç”©–ª”©—Ö\" —Ç–∞–ª–∞–∞—Ä –∞—Å—É—É–∂, –ª–∏–∑–∏–Ω–≥/–∑—ç—ç–ª—Ç—ç–π —Ö–æ–ª–±–æ–æ—Ç–æ–π —Ç”©–ª–±”©—Ä —Ö–∏–π—Ö –∑–∞–∞–≤—Ä—ã–≥ —Ö“Ø—Å—Å—ç–Ω —É—á—Ä–∞–∞—Å –≥–∞—Ä —É—Ç–∞—Å –ª–∏–∑–∏–Ω–≥ —Ç”©—Ä”©–ª–¥ —Ö–∞–º–≥–∏–π–Ω —Ç–æ—Ö–∏—Ä–Ω–æ.', 'abstain': False, 'selected_index': 4, 'path_mn': 'Toki > “Æ–π–ª—á–∏–ª–≥—ç—ç > –ì–∞—Ä —É—Ç–∞—Å –ª–∏–∑–∏–Ω–≥ > –¢”©—Ö”©”©—Ä”©–º–∂ –±–æ–ª–æ–Ω –¥–∞–≥–∞–ª–¥–∞—Ö —Ö—ç—Ä—ç–≥—Å—ç–ª—Ç—ç–π —Ö–æ–ª–±–æ–æ—Ç–æ–π'}\n"
     ]
    }
   ],
   "source": [
    "xd = await run_smartclassifier(tickets.at[6, \"ticket\"])\n",
    "print(xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ticket': '–ú—è–≥–º–∞—Ä–∂–∞—Ä–≥–∞–ª –ë—è–º–±–∞–∂–∞–≤\\': \"Get started\"\\n\\'customer service\\': \"–°–∞–π–Ω –±–∞–π–Ω–∞ —É—É? üëã Toki –∞–ø–ø-—Ç–∞–π —Ö–æ–ª–±–æ–æ—Ç–æ–π –∞—Å—É—É—Ö –∑“Ø–π–ª—ç—ç –±–∏—á—ç—ç—Ä—ç–π? üòä\"\\n\\'–ú—è–≥–º–∞—Ä–∂–∞—Ä–≥–∞–ª –ë—è–º–±–∞–∂–∞–≤\\': \"–ê–∂–∏–ª—Ç–∞–Ω—Ç–∞–π —Ö–æ–ª–±–æ–≥–¥–æ—Ö\"\\n\\'–ú—è–≥–º–∞—Ä–∂–∞—Ä–≥–∞–ª –ë—è–º–±–∞–∂–∞–≤\\': \"–≥–∞—Ä —É—Ç–∞—Å–Ω—ã –∑—ç—ç–ª —ç—Ä–≥—ç–Ω —è–∞–∂ —Ç”©–ª”©—Ö –≤—ç\"\\n\\'customer service\\': \"–°–∞–π–Ω –±–∞–π–Ω–∞ —É—É? –ë–∏ –°–æ–Ω–¥–æ—Ä –±–∞–π–Ω–∞ üôã\\u200d‚ôÄÔ∏è–¢–∞–Ω–¥ —é—É–≥–∞–∞—Ä —Ç—É—Å–ª–∞—Ö –≤—ç?\"\\n\\'–ú—è–≥–º–∞—Ä–∂–∞—Ä–≥–∞–ª –ë—è–º–±–∞–∂–∞–≤\\': \"–≥–∞—Ä —É—Ç–∞—Å–Ω—ã –∑—ç—ç–ª —Ç”©–ª”©—Ö –≥—ç—Å—ç–Ω —Ö–∞–∞—à–∞–∞ —è–∞–∂ –æ—Ä–∂ —Ç”©–ª”©—Ö –≤—ç?\"\\n\\'customer service\\': \"–¢–∞ –•—ç—Ç—ç–≤—á- Toki –ª–∏–∑–∏–Ω–≥ —Ü—ç—Å—ç—ç—Ä —Ö–∞–Ω–¥–∞–∞–¥ —Ç”©–ª–±”©—Ä —Ç”©–ª”©–ª—Ç”©”© —Ö–∏–π–≥—ç—ç—Ä—ç–π.\"', 'domain': 'Toki', 'category_1': '–•—ç—Ç—ç–≤—á', 'category_2': '–ö—Ä–µ–¥–∏—Ç —ç—Ä–≥—ç–Ω —Ç”©–ª”©–ª—Ç—Ç—ç–π —Ö–æ–ª–±–æ–æ—Ç–æ–π', 'category_3': 'L2-–≠—Ä–≥—ç–Ω —Ç”©–ª”©–ª—Ç –æ—Ä—É—É–ª—Å–∞–Ω'}\n"
     ]
    }
   ],
   "source": [
    "susta = run_pipeline(tickets.at[6, \"ticket\"], \"data/cleaned.csv\")\n",
    "print(susta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "{'best_path': {'L1_domain': {'id': 'dom.1b59a5fdf0ef', 'confidence': 0.9, 'name': 'Toki'}, 'L2_cat1': {'id': 'cat1.38f67d7524e1', 'confidence': 0.9, 'name': '“Æ–π–ª—á–∏–ª–≥—ç—ç'}, 'L3_cat2': {'id': 'cat2.aae242753c1c', 'confidence': 0.85, 'name': '–ì–∞—Ä —É—Ç–∞—Å –ª–∏–∑–∏–Ω–≥'}, 'L4_cat3': {'id': 'cat3.b3c7195654a0', 'confidence': 0.85, 'name': '–¢”©—Ö”©”©—Ä”©–º–∂ –±–æ–ª–æ–Ω –¥–∞–≥–∞–ª–¥–∞—Ö —Ö—ç—Ä—ç–≥—Å—ç–ª—Ç—ç–π —Ö–æ–ª–±–æ–æ—Ç–æ–π'}}, 'rationale': '–°–æ–Ω–≥–æ—Å–æ–Ω –∑–∞–º: Toki > “Æ–π–ª—á–∏–ª–≥—ç—ç > –ì–∞—Ä —É—Ç–∞—Å –ª–∏–∑–∏–Ω–≥ > –¢”©—Ö”©”©—Ä”©–º–∂ –±–æ–ª–æ–Ω –¥–∞–≥–∞–ª–¥–∞—Ö —Ö—ç—Ä—ç–≥—Å—ç–ª—Ç—ç–π —Ö–æ–ª–±–æ–æ—Ç–æ–π. –•—ç—Ä—ç–≥–ª—ç–≥—á \"–≥–∞—Ä —É—Ç–∞—Å–Ω—ã –∑—ç—ç–ª/–ª–∏–∑–∏–Ω–≥ —ç—Ä–≥—ç–Ω —Ç”©–ª”©—Ö\" —Ç–∞–ª–∞–∞—Ä –∑–∞–∞–≤–∞—Ä —Ö“Ø—Å—ç–∂ –±–∞–π–≥–∞–∞–≥–∞–∞—Å —ç–Ω—ç –Ω—å –≥–∞—Ä —É—Ç–∞—Å –ª–∏–∑–∏–Ω–≥, —Ç”©—Ö”©”©—Ä”©–º–∂—Ç—ç–π —Ö–æ–ª–±–æ–æ—Ç–æ–π —Ö–∞–º–≥–∏–π–Ω —Ç–æ—Ö–∏—Ä–æ—Ö –∞–Ω–≥–∏–ª–∞–ª –≥—ç–∂ “Ø–∑—ç–≤.', 'abstain': False, 'selected_index': 4, 'path_mn': 'Toki > “Æ–π–ª—á–∏–ª–≥—ç—ç > –ì–∞—Ä —É—Ç–∞—Å –ª–∏–∑–∏–Ω–≥ > –¢”©—Ö”©”©—Ä”©–º–∂ –±–æ–ª–æ–Ω –¥–∞–≥–∞–ª–¥–∞—Ö —Ö—ç—Ä—ç–≥—Å—ç–ª—Ç—ç–π —Ö–æ–ª–±–æ–æ—Ç–æ–π'}\n",
      "Toki>–•—ç—Ç—ç–≤—á>–ö—Ä–µ–¥–∏—Ç —ç—Ä–≥—ç–Ω —Ç”©–ª”©–ª—Ç—Ç—ç–π —Ö–æ–ª–±–æ–æ—Ç–æ–π>L2-–≠—Ä–≥—ç–Ω —Ç”©–ª”©–ª—Ç –æ—Ä—É—É–ª—Å–∞–Ω\n"
     ]
    }
   ],
   "source": [
    "basta = await pipeline.run(tickets.at[6, \"ticket\"])\n",
    "langfuse.shutdown()\n",
    "susta = await run_pipeline(tickets.at[6, \"ticket\"], \"data/cleaned.csv\")\n",
    "print(susta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobile>–î–∞—Ç–∞>–î–∞—Ç–∞ –±–∞–≥—Ü—É—É–¥—Ç–∞–π —Ö–æ–ª–±–æ–æ—Ç–æ–π>Other/Unknown\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>–î—É–≥–∞–∞—Ä>–î—É–≥–∞–∞—Ä —Ö–∞–¥–≥–∞–ª–∞—Ö—Ç–∞–π —Ö–æ–ª–±–æ–æ—Ç–æ–π>L2-–î—É–≥–∞–∞—Ä —Ö–∞–¥–≥–∞–ª—É—É–ª–∞—Ö —Ö“Ø—Å—ç–ª—Ç\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Path terminates at Cat2 for 'Mobile -> “Æ–Ω–¥—Å—ç–Ω “Ø–π–ª—á–∏–ª–≥—ç—ç -> –ì–∞—Ä —É—Ç–∞—Å–Ω—ã —Ç–æ—Ö–∏—Ä–≥–æ–æ—Ç–æ–π —Ö–æ–ª–±–æ–æ—Ç–æ–π'.\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>–î—É–≥–∞–∞—Ä>–®–∏–Ω—ç —Ö—ç—Ä—ç–≥–ª—ç–≥—á—Ç—ç–π —Ö–æ–ª–±–æ–æ—Ç–æ–π>L2-Unitel app —à–∏–Ω—ç –¥—É–≥–∞–∞—Ä—ã–Ω QR —É–Ω—à–∏–≥–¥–∞—Ö–≥“Ø–π –±–∞–π–≥–∞–∞–≥–∞–∞—Å —à–∞–ª—Ç–≥–∞–∞–ª—Å–∞–Ω\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Path terminates at Cat2 for 'Mobile -> –ù—ç–º—ç–ª—Ç “Ø–π–ª—á–∏–ª–≥—ç—ç -> –•“Ø—Å—ç–ª—Ç –Ω—ç–º—ç–ª—Ç “Ø–π–ª—á–∏–ª–≥—ç—ç-1444'.\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>–ù—ç–≥–∂>–¶—ç–Ω—ç–≥–ª—ç–≥—á –∫–∞—Ä—Ç—Ç–∞–π —Ö–æ–ª–±–æ–æ—Ç–æ–π>L2-–•—ç—Ä—ç–≥–ª—ç–≥—á—ç—ç—Å —à–∞–ª—Ç–≥–∞–∞–ª—Å–∞–Ω\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>–î—É–≥–∞–∞—Ä>–î—É–≥–∞–∞—Ä —Ö–∞–∞–∂, –Ω—ç—ç–ª–≥—ç—Ö—Ç—ç–π —Ö–æ–ª–±–æ–æ—Ç–æ–π>L2-–î—É–≥–∞–∞—Ä —É—Å—Ç–≥—É—É–ª–∞—Ö —Ö“Ø—Å—ç–ª—Ç\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Path terminates at Cat2 for 'Mobile -> “Æ–Ω–¥—Å—ç–Ω “Ø–π–ª—á–∏–ª–≥—ç—ç -> –ì–∞—Ä —É—Ç–∞—Å–Ω—ã —Ç–æ—Ö–∏—Ä–≥–æ–æ—Ç–æ–π —Ö–æ–ª–±–æ–æ—Ç–æ–π'.\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Path terminates at Cat2 for 'Mobile -> –ù—ç–º—ç–ª—Ç “Ø–π–ª—á–∏–ª–≥—ç—ç -> –•“Ø—Å—ç–ª—Ç –Ω—ç–º—ç–ª—Ç “Ø–π–ª—á–∏–ª–≥—ç—ç-1444'.\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>–ù—ç–º—ç–ª—Ç “Ø–π–ª—á–∏–ª–≥—ç—ç>–î—É—É–¥–ª–∞–≥–∞ —à–∏–ª–∂“Ø“Ø–ª—ç—Ö “Ø–π–ª—á–∏–ª–≥—ç—ç>L2- –î—É—É–¥–ª–∞–≥–∞ —à–∏–ª–∂“Ø“Ø–ª—ç—Ö —Ö“Ø—Å—ç–ª—Ç\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>–î–∞—Ç–∞>–î–∞—Ç–∞ —É–Ω—à–∏—Ö–≥“Ø–π, —Ö—É—Ä–¥ —É–¥–∞–∞–Ω –±–∞–π–≥–∞–∞>L1-–î–∞—Ç–∞ —Ö—É—Ä–¥ —É–Ω–∞–∞–≥“Ø–π —Ö—ç—Ä—ç–≥–ª—ç–≥—á—ç—ç—Å —à–∞–ª—Ç–≥–∞–∞–ª—Å–∞–Ω\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Path terminates at Cat2 for 'Mobile -> “Æ–Ω–¥—Å—ç–Ω “Ø–π–ª—á–∏–ª–≥—ç—ç -> –ì–∞—Ä —É—Ç–∞—Å–Ω—ã —Ç–æ—Ö–∏—Ä–≥–æ–æ—Ç–æ–π —Ö–æ–ª–±–æ–æ—Ç–æ–π'.\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Toki>–ë“Ø—Ä—Ç–≥—ç–ª, —Ç–æ—Ö–∏—Ä–≥–æ–æ>–ì“Ø–π–ª–≥—ç—ç–Ω–∏–π –Ω—É—É—Ü “Ø–≥—Ç—ç–π —Ö–æ–ª–±–æ–æ—Ç–æ–π>L2-–ù—É—É—Ü “Ø–≥ —Å—ç—Ä–≥—ç—ç—Ö OTP –∫–æ–¥ –∏—Ä—ç—ç–≥“Ø–π\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Path terminates at Cat2 for 'Mobile -> “Æ–Ω–¥—Å—ç–Ω “Ø–π–ª—á–∏–ª–≥—ç—ç -> –ì–∞—Ä —É—Ç–∞—Å–Ω—ã —Ç–æ—Ö–∏—Ä–≥–æ–æ—Ç–æ–π —Ö–æ–ª–±–æ–æ—Ç–æ–π'.\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>–î—É–≥–∞–∞—Ä>–î—É—É–¥–ª–∞–≥–∞ —Ö–∏–π–∂ –±–æ–ª–æ—Ö–≥“Ø–π –±–∞–π–≥–∞–∞>L2-–•—ç—Ä—ç–≥–ª—ç–≥—á—ç—ç—Å —à–∞–ª—Ç–≥–∞–∞–ª—Å–∞–Ω –¥—É—É–¥–ª–∞–≥–∞ —Ö–∏–π—Ö—ç–¥ —Ö—ç–≤–∏–π–Ω\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Toki>Toki Mobile>–î—É–≥–∞–∞—Ä>Other/Unknown\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>–î–∞—Ç–∞>–ó–∞—Ä—Ü—É—É–ª–∞–ª—Ç—Ç–∞–π —Ö–æ–ª–±–æ–æ—Ç–æ–π>L2-–•—ç—Ä—ç–≥–ª—ç–≥—á —Ö—ç—Ä—ç–≥–ª—ç—ç–≥—ç—ç —Ö“Ø–ª—ç—ç–Ω –∑”©–≤—à”©”©—Ä”©”©–≥“Ø–π–≥—ç—ç—Å —à–∞–ª—Ç–≥–∞–∞–ª—Å–∞–Ω\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>–î—É–≥–∞–∞—Ä>–î—É–≥–∞–∞—Ä —Ö–∞–∞–∂, –Ω—ç—ç–ª–≥—ç—Ö—Ç—ç–π —Ö–æ–ª–±–æ–æ—Ç–æ–π>L2-–î—É–≥–∞–∞—Ä –Ω—ç—ç—Ö—ç–¥ /Reactivation Required/ –∞–ª–¥–∞–∞ –∑–∞–∞—Å–Ω–∞–∞—Å —à–∞–ª—Ç–≥–∞–∞–ª—Å–∞–Ω*\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>–î—É–≥–∞–∞—Ä>–î—É–≥–∞–∞—Ä —Ö–∞–¥–≥–∞–ª–∞—Ö—Ç–∞–π —Ö–æ–ª–±–æ–æ—Ç–æ–π>L2-Unitel app-—Ä –¥—É–≥–∞–∞—Ä —Ö–∞–¥–≥–∞–ª–∞—Ö “Ø–π–ª—á–∏–ª–≥—ç—ç –∞–º–∂–∏–ª—Ç–≥“Ø–π –±–æ–ª—Å–Ω–æ–æ—Å —à–∞–ª—Ç–≥–∞–∞–ª—Å–∞–Ω*\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>–î–∞—Ç–∞>–î–∞—Ç–∞ “Ø–ª–¥—ç–≥–¥—ç–ª—Ç—ç–π —Ö–æ–ª–±–æ–æ—Ç–æ–π>L2-–î–∞—Ç–∞ “Ø–ª–¥—ç–≥–¥—ç–ª –±—É—Ä—É—É —Ö–∞—Ä—É—É–ª—Å–∞–Ω–∞–∞—Å —à–∞–ª—Ç–≥–∞–∞–ª—Å–∞–Ω*\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "Mobile>–î—É–≥–∞–∞—Ä>–®–∏–Ω—ç —Ö—ç—Ä—ç–≥–ª—ç–≥—á—Ç—ç–π —Ö–æ–ª–±–æ–æ—Ç–æ–π>Other/Unknown\n",
      "Initializing Smart Classifier (Domain‚ÜíCat1‚ÜíCat2‚ÜíCat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n"
     ]
    }
   ],
   "source": [
    "for ticket in tickets['case']:\n",
    "    final_categorization = await pipeline.run(ticket)\n",
    "    result = await run_smartclassifier(ticket)\n",
    "    keys_in_order = [\"domain\", \"category_1\", \"category_2\", \"category_3\"]\n",
    "    valid_parts = [final_categorization.get(key) for key in keys_in_order]\n",
    "    non_empty_parts = [\n",
    "        part for part in valid_parts if part is not None and str(part).strip() != ''\n",
    "    ]\n",
    "    output = \" > \".join(non_empty_parts)\n",
    "    final_categorizations.append(output)\n",
    "    kb_results.append(result[\"path_mn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets['seq agent'] = final_categorizations\n",
    "tickets['kb agent'] = kb_results\n",
    "tickets.to_csv(\"data/evaluatednewfile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell5 ‚Äî quick scores/preview\n",
    "import pandas as pd\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "df = pd.read_csv(\"data/evaluatedtwofold.csv\")\n",
    "\n",
    "\n",
    "def part_match(a: str, b: str) -> float:\n",
    "    \"\"\"\n",
    "    Compares path parts separated by '>' and returns the ratio of matching,\n",
    "    order-sensitive, left-to-right (prefix) matches.\n",
    "    \"\"\"\n",
    "    if not isinstance(a, str):\n",
    "        a = \"\"\n",
    "    if not isinstance(b, str):\n",
    "        b = \"\"\n",
    "    pa = [p.strip() for p in a.split(\">\") if str(p).strip()]\n",
    "    pb = [p.strip() for p in b.split(\">\") if str(p).strip()]\n",
    "    if not pa and not pb:\n",
    "        return 1.0\n",
    "    match = 0\n",
    "    for i, (xa, xb) in enumerate(zip(pa, pb)):\n",
    "        if xa == xb:\n",
    "            match += 1\n",
    "        else:\n",
    "            break  # stop at first mismatch (prefix agreement)\n",
    "    denom = max(len(pa), len(pb)) or 1\n",
    "    return match / denom\n",
    "\n",
    "\n",
    "def safe_str(x):\n",
    "    return \"\" if pd.isna(x) else str(x)\n",
    "\n",
    "\n",
    "# Choose which model columns you want to compare against the employee column\n",
    "EMP_COL = \"employee\"\n",
    "SEQ_COL = \"seq agent\"\n",
    "KB_COL = \"kb agent\"\n",
    "\n",
    "df[\"Fuzzy similarity\"] = df.apply(\n",
    "    lambda r: fuzz.token_set_ratio(safe_str(r[EMP_COL]), safe_str(r[SEQ_COL])) / 100.0,\n",
    "    axis=1,\n",
    ")\n",
    "df[\"Fuzzy similarity (kb)\"] = df.apply(\n",
    "    lambda r: fuzz.token_set_ratio(safe_str(r[EMP_COL]), safe_str(r[KB_COL])) / 100.0,\n",
    "    axis=1,\n",
    ")\n",
    "df[\"Part match (seq)\"] = df.apply(\n",
    "    lambda r: part_match(safe_str(r[EMP_COL]), safe_str(r[SEQ_COL])), axis=1\n",
    ")\n",
    "df[\"Part match (kb)\"] = df.apply(\n",
    "    lambda r: part_match(safe_str(r[EMP_COL]), safe_str(r[KB_COL])), axis=1\n",
    ")\n",
    "\n",
    "# Optional: if you later add 2.5 variants, repeat with those columns:\n",
    "for col in [\"seq agent 2.5\", \"kb agent 2.5\"]:\n",
    "    if col in df.columns:\n",
    "        df[f\"Fuzzy similarity ({col})\"] = df.apply(\n",
    "            lambda r: fuzz.token_set_ratio(safe_str(r[EMP_COL]), safe_str(r[col]))\n",
    "            / 100.0,\n",
    "            axis=1,\n",
    "        )\n",
    "        df[f\"Part match ({col})\"] = df.apply(\n",
    "            lambda r: part_match(safe_str(r[EMP_COL]), safe_str(r[col])), axis=1\n",
    "        )\n",
    "\n",
    "preview_cols = [\n",
    "    \"Case ID\",\n",
    "    \"ticket\",\n",
    "    \"employee\",\n",
    "    SEQ_COL,\n",
    "    KB_COL,\n",
    "    \"Fuzzy similarity\",\n",
    "    \"Fuzzy similarity (kb)\",\n",
    "    \"Part match (seq)\",\n",
    "    \"Part match (kb)\",\n",
    "] + [\n",
    "    c\n",
    "    for c in df.columns\n",
    "    if c.startswith(\"Fuzzy similarity (seq agent 2.5\")\n",
    "    or c.startswith(\"Fuzzy similarity (kb agent 2.5\")\n",
    "]\n",
    "preview = df[[c for c in preview_cols if c in df.columns]].head(10)\n",
    "\n",
    "# Save and show\n",
    "out_path = \"data/scored_evaluation.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "print(f\"Saved: {out_path}\")\n",
    "preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = await classifier.classify(tickets.at[6, \"ticket\"])\n",
    "print(xd)\n",
    "basta = await pipeline.run(tickets.at[6, \"ticket\"])\n",
    "langfuse.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
