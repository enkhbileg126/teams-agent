{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ.setdefault(\"GRPC_VERBOSITY\", \"NONE\")\n",
    "os.environ.setdefault(\"GLOG_minloglevel\", \"2\")\n",
    "from src.pipeline_4_agent import SequentialAgentPipeline\n",
    "from src.retrieval_then_llm import SmartClassifier, run_smartclassifier\n",
    "import pandas as pd\n",
    "from langfuse import Langfuse, get_client\n",
    "\n",
    "langfuse = get_client()\n",
    "tickets = pd.read_csv(\"data/dataset_for_categorization.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing taxonomy from data/cleaned.csv...\n"
     ]
    }
   ],
   "source": [
    "pipeline = SequentialAgentPipeline(\"data/cleaned.csv\")\n",
    "final_categorizations = []\n",
    "kb_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Smart Classifier (Domain→Cat1→Cat2→Cat3)...\n",
      "Loading existing FAISS index from taxonomy.index...\n",
      "{'best_path': {'L1_domain': {'id': 'dom.1b59a5fdf0ef', 'confidence': 0.9, 'name': 'Toki'}, 'L2_cat1': {'id': 'cat1.38f67d7524e1', 'confidence': 0.9, 'name': 'Үйлчилгээ'}, 'L3_cat2': {'id': 'cat2.aae242753c1c', 'confidence': 0.85, 'name': 'Гар утас лизинг'}, 'L4_cat3': {'id': 'cat3.b3c7195654a0', 'confidence': 0.85, 'name': 'Төхөөрөмж болон дагалдах хэрэгсэлтэй холбоотой'}}, 'rationale': 'Сонгосон зам: Toki > Үйлчилгээ > Гар утас лизинг > Төхөөрөмж болон дагалдах хэрэгсэлтэй холбоотой. Хэрэглэгч \"гар утасны зээл/лизинг эргэн төлөх\" талаар заавар хүсэж байгаагаас энэ нь гар утас лизинг, төхөөрөмжтэй холбоотой хамгийн тохирох ангилал гэж үзэв.', 'abstain': False, 'selected_index': 4, 'path_mn': 'Toki > Үйлчилгээ > Гар утас лизинг > Төхөөрөмж болон дагалдах хэрэгсэлтэй холбоотой'}\n",
      "Toki>Хэтэвч>Кредит эргэн төлөлттэй холбоотой>L2-Эргэн төлөлт оруулсан\n"
     ]
    }
   ],
   "source": [
    "xd = await run_smartclassifier(tickets.at[6, \"ticket\"])\n",
    "print(xd)\n",
    "basta = await pipeline.run(tickets.at[6, \"ticket\"])\n",
    "langfuse.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticket in tickets['ticket']:\n",
    "    final_categorization = await pipeline.run(ticket)\n",
    "    result = await classifier.classify(ticket)\n",
    "    keys_in_order = [\"domain\", \"category_1\", \"category_2\", \"category_3\"]\n",
    "    valid_parts = [final_categorization.get(key) for key in keys_in_order]\n",
    "    non_empty_parts = [\n",
    "        part for part in valid_parts if part is not None and str(part).strip() != ''\n",
    "    ]\n",
    "    output = \" > \".join(non_empty_parts)\n",
    "    final_categorizations.append(output)\n",
    "    kb_results.append(result[\"path_mn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets['seq agent'] = final_categorizations\n",
    "tickets['kb agent'] = kb_results\n",
    "tickets.to_csv(\"data/evaluatedtwofold.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell5 — quick scores/preview\n",
    "import pandas as pd\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "df = pd.read_csv(\"data/evaluatedtwofold.csv\")\n",
    "\n",
    "\n",
    "def part_match(a: str, b: str) -> float:\n",
    "    \"\"\"\n",
    "    Compares path parts separated by '>' and returns the ratio of matching,\n",
    "    order-sensitive, left-to-right (prefix) matches.\n",
    "    \"\"\"\n",
    "    if not isinstance(a, str):\n",
    "        a = \"\"\n",
    "    if not isinstance(b, str):\n",
    "        b = \"\"\n",
    "    pa = [p.strip() for p in a.split(\">\") if str(p).strip()]\n",
    "    pb = [p.strip() for p in b.split(\">\") if str(p).strip()]\n",
    "    if not pa and not pb:\n",
    "        return 1.0\n",
    "    match = 0\n",
    "    for i, (xa, xb) in enumerate(zip(pa, pb)):\n",
    "        if xa == xb:\n",
    "            match += 1\n",
    "        else:\n",
    "            break  # stop at first mismatch (prefix agreement)\n",
    "    denom = max(len(pa), len(pb)) or 1\n",
    "    return match / denom\n",
    "\n",
    "\n",
    "def safe_str(x):\n",
    "    return \"\" if pd.isna(x) else str(x)\n",
    "\n",
    "\n",
    "# Choose which model columns you want to compare against the employee column\n",
    "EMP_COL = \"employee\"\n",
    "SEQ_COL = \"seq agent\"\n",
    "KB_COL = \"kb agent\"\n",
    "\n",
    "df[\"Fuzzy similarity\"] = df.apply(\n",
    "    lambda r: fuzz.token_set_ratio(safe_str(r[EMP_COL]), safe_str(r[SEQ_COL])) / 100.0,\n",
    "    axis=1,\n",
    ")\n",
    "df[\"Fuzzy similarity (kb)\"] = df.apply(\n",
    "    lambda r: fuzz.token_set_ratio(safe_str(r[EMP_COL]), safe_str(r[KB_COL])) / 100.0,\n",
    "    axis=1,\n",
    ")\n",
    "df[\"Part match (seq)\"] = df.apply(\n",
    "    lambda r: part_match(safe_str(r[EMP_COL]), safe_str(r[SEQ_COL])), axis=1\n",
    ")\n",
    "df[\"Part match (kb)\"] = df.apply(\n",
    "    lambda r: part_match(safe_str(r[EMP_COL]), safe_str(r[KB_COL])), axis=1\n",
    ")\n",
    "\n",
    "# Optional: if you later add 2.5 variants, repeat with those columns:\n",
    "for col in [\"seq agent 2.5\", \"kb agent 2.5\"]:\n",
    "    if col in df.columns:\n",
    "        df[f\"Fuzzy similarity ({col})\"] = df.apply(\n",
    "            lambda r: fuzz.token_set_ratio(safe_str(r[EMP_COL]), safe_str(r[col]))\n",
    "            / 100.0,\n",
    "            axis=1,\n",
    "        )\n",
    "        df[f\"Part match ({col})\"] = df.apply(\n",
    "            lambda r: part_match(safe_str(r[EMP_COL]), safe_str(r[col])), axis=1\n",
    "        )\n",
    "\n",
    "preview_cols = [\n",
    "    \"Case ID\",\n",
    "    \"ticket\",\n",
    "    \"employee\",\n",
    "    SEQ_COL,\n",
    "    KB_COL,\n",
    "    \"Fuzzy similarity\",\n",
    "    \"Fuzzy similarity (kb)\",\n",
    "    \"Part match (seq)\",\n",
    "    \"Part match (kb)\",\n",
    "] + [\n",
    "    c\n",
    "    for c in df.columns\n",
    "    if c.startswith(\"Fuzzy similarity (seq agent 2.5\")\n",
    "    or c.startswith(\"Fuzzy similarity (kb agent 2.5\")\n",
    "]\n",
    "preview = df[[c for c in preview_cols if c in df.columns]].head(10)\n",
    "\n",
    "# Save and show\n",
    "out_path = \"data/scored_evaluation.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "print(f\"Saved: {out_path}\")\n",
    "preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = await classifier.classify(tickets.at[6, \"ticket\"])\n",
    "print(xd)\n",
    "basta = await pipeline.run(tickets.at[6, \"ticket\"])\n",
    "langfuse.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
